{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 Transformer Model for Sarcasm Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lfrostbyte/anaconda3/envs/CS3264/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lfrostbyte/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/lfrostbyte/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lfrostbyte/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import copy\n",
    "import shap\n",
    "import gc\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2ForSequenceClassification\n",
    "from sklearn.metrics import recall_score, accuracy_score, f1_score, precision_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "# https://colab.research.google.com/drive/1dMTdO5vxdVX0NA2Qe7AV9WGEy8ZH67Xn?usp=sharing#scrollTo=afcc233b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2425, 16)\n",
      "(5284, 16)\n",
      "(2882, 16)\n",
      "(2967, 16)\n",
      "(2743, 16)\n",
      "(2068, 16)\n",
      "Preprocess labels\n",
      "(4811, 16)\n",
      "(13558, 16)\n",
      "13558\n",
      "Oversampling\n",
      "(13558, 16)\n",
      "(13558, 16)\n",
      "1696\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>date</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_description</th>\n",
       "      <th>state_info</th>\n",
       "      <th>true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_false_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "      <th>context</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4425</td>\n",
       "      <td>0</td>\n",
       "      <td>The people in Massachusetts like (the state he...</td>\n",
       "      <td>October 18, 2011</td>\n",
       "      <td>health care;polls and public opinion;states</td>\n",
       "      <td>mitt romney</td>\n",
       "      <td>Mitt Romney is a U.S. senator from Utah. HeÂ ra...</td>\n",
       "      <td>national</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>Hanover, N.H</td>\n",
       "      <td>Romney has strong support for this . A recent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3378</td>\n",
       "      <td>1</td>\n",
       "      <td>Said Planned Parenthood's early objective was ...</td>\n",
       "      <td>March 15, 2011</td>\n",
       "      <td>abortion</td>\n",
       "      <td>herman cain</td>\n",
       "      <td>Herman Cain is an author, columnist and talk r...</td>\n",
       "      <td>georgia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>a talk at a conservative think tank</td>\n",
       "      <td>Why would Sanger try to destroy a race of peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6016</td>\n",
       "      <td>0</td>\n",
       "      <td>There are close to 900,000 unemployed veterans...</td>\n",
       "      <td>July 23, 2012</td>\n",
       "      <td>economy;military;veterans</td>\n",
       "      <td>sanford bishop</td>\n",
       "      <td>Democrat Sanford Bishop represents Georgia's 2...</td>\n",
       "      <td>georgia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>an online video of an earlier speech</td>\n",
       "      <td>Veterans are faring better than U.S. workers a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>Hillary stood up for universal health care whe...</td>\n",
       "      <td>October 4, 2007</td>\n",
       "      <td>health care</td>\n",
       "      <td>hillary clinton</td>\n",
       "      <td>Hillary Clinton was the 2016 Democratic nomine...</td>\n",
       "      <td>national</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>70</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>Iowa and New Hampshire</td>\n",
       "      <td>But the Clinton campaign says she used her inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10596</td>\n",
       "      <td>0</td>\n",
       "      <td>The United States has the highest incarceratio...</td>\n",
       "      <td>August 5, 2015</td>\n",
       "      <td>criminal justice;crime</td>\n",
       "      <td>jim webb</td>\n",
       "      <td>Jim Webb is running for president of the Unite...</td>\n",
       "      <td>virginia</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a web post</td>\n",
       "      <td>Webb said the U.S. has the highest incarcerati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27111</th>\n",
       "      <td>10653</td>\n",
       "      <td>0</td>\n",
       "      <td>Says Ron Johnson \"opposes entirely a federal m...</td>\n",
       "      <td>August 18, 2015</td>\n",
       "      <td>agriculture;economy;jobs;labor;government regu...</td>\n",
       "      <td>russ feingold</td>\n",
       "      <td>Russ Feingold served as a Democratic U.S. Sena...</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>a speech</td>\n",
       "      <td>Johnson opposes a raise to $15, the statement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27112</th>\n",
       "      <td>10010</td>\n",
       "      <td>1</td>\n",
       "      <td>President Barack Obama's veto of the Keystone ...</td>\n",
       "      <td>February 24, 2015</td>\n",
       "      <td>energy;jobs</td>\n",
       "      <td>tom graves</td>\n",
       "      <td>Tom Graves represents Georgia's 9th Congressio...</td>\n",
       "      <td>georgia</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a press release</td>\n",
       "      <td>Both Democrats and Republicans have spun the n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27113</th>\n",
       "      <td>5740</td>\n",
       "      <td>1</td>\n",
       "      <td>Says \"Oregon is one of only three states that ...</td>\n",
       "      <td>May 30, 2012</td>\n",
       "      <td>environment;jobs;message machine 2012;recreation</td>\n",
       "      <td>stop gillnetting now</td>\n",
       "      <td>The Stop Gillnetting Now campaign is working t...</td>\n",
       "      <td>oregon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>campaign press statement</td>\n",
       "      <td>There are some states that donât depend on com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27114</th>\n",
       "      <td>18968</td>\n",
       "      <td>0</td>\n",
       "      <td>Republican elected officials, a network of pro...</td>\n",
       "      <td>November 17, 2020</td>\n",
       "      <td>fake news;coronavirus</td>\n",
       "      <td>jb pritzker</td>\n",
       "      <td>J.B. Pritzker is Illinois' 43rd governor and a...</td>\n",
       "      <td>illinois</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>remarks at a news conference</td>\n",
       "      <td>Pritzker said \"Republican elected officials, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27115</th>\n",
       "      <td>7125</td>\n",
       "      <td>0</td>\n",
       "      <td>Says \"PPS employees have paid their own PERS c...</td>\n",
       "      <td>January 22, 2013</td>\n",
       "      <td>education;pensions;unions;workers</td>\n",
       "      <td>portland public schools</td>\n",
       "      <td>Portland Public Schools is Oregon's largest sc...</td>\n",
       "      <td>oregon</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a letter to Portlanders</td>\n",
       "      <td>Cities and counties for 85 percent of workers....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27116 rows Ã 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                          statement  \\\n",
       "0       4425      0  The people in Massachusetts like (the state he...   \n",
       "1       3378      1  Said Planned Parenthood's early objective was ...   \n",
       "2       6016      0  There are close to 900,000 unemployed veterans...   \n",
       "3         95      1  Hillary stood up for universal health care whe...   \n",
       "4      10596      0  The United States has the highest incarceratio...   \n",
       "...      ...    ...                                                ...   \n",
       "27111  10653      0  Says Ron Johnson \"opposes entirely a federal m...   \n",
       "27112  10010      1  President Barack Obama's veto of the Keystone ...   \n",
       "27113   5740      1  Says \"Oregon is one of only three states that ...   \n",
       "27114  18968      0  Republican elected officials, a network of pro...   \n",
       "27115   7125      0  Says \"PPS employees have paid their own PERS c...   \n",
       "\n",
       "                    date                                            subject  \\\n",
       "0       October 18, 2011        health care;polls and public opinion;states   \n",
       "1         March 15, 2011                                           abortion   \n",
       "2          July 23, 2012                          economy;military;veterans   \n",
       "3        October 4, 2007                                        health care   \n",
       "4         August 5, 2015                             criminal justice;crime   \n",
       "...                  ...                                                ...   \n",
       "27111    August 18, 2015  agriculture;economy;jobs;labor;government regu...   \n",
       "27112  February 24, 2015                                        energy;jobs   \n",
       "27113       May 30, 2012   environment;jobs;message machine 2012;recreation   \n",
       "27114  November 17, 2020                              fake news;coronavirus   \n",
       "27115   January 22, 2013                  education;pensions;unions;workers   \n",
       "\n",
       "                       speaker  \\\n",
       "0                  mitt romney   \n",
       "1                  herman cain   \n",
       "2               sanford bishop   \n",
       "3              hillary clinton   \n",
       "4                     jim webb   \n",
       "...                        ...   \n",
       "27111            russ feingold   \n",
       "27112               tom graves   \n",
       "27113     stop gillnetting now   \n",
       "27114              jb pritzker   \n",
       "27115  portland public schools   \n",
       "\n",
       "                                     speaker_description state_info  \\\n",
       "0      Mitt Romney is a U.S. senator from Utah. HeÂ ra...   national   \n",
       "1      Herman Cain is an author, columnist and talk r...    georgia   \n",
       "2      Democrat Sanford Bishop represents Georgia's 2...    georgia   \n",
       "3      Hillary Clinton was the 2016 Democratic nomine...   national   \n",
       "4      Jim Webb is running for president of the Unite...   virginia   \n",
       "...                                                  ...        ...   \n",
       "27111  Russ Feingold served as a Democratic U.S. Sena...  wisconsin   \n",
       "27112  Tom Graves represents Georgia's 9th Congressio...    georgia   \n",
       "27113  The Stop Gillnetting Now campaign is working t...     oregon   \n",
       "27114  J.B. Pritzker is Illinois' 43rd governor and a...   illinois   \n",
       "27115  Portland Public Schools is Oregon's largest sc...     oregon   \n",
       "\n",
       "       true_counts  mostly_true_counts  half_true_counts  mostly_false_counts  \\\n",
       "0               31                  33                58                   35   \n",
       "1                0                   3                 5                    4   \n",
       "2                1                   1                 0                    0   \n",
       "3               72                  76                70                   43   \n",
       "4                3                   4                 2                    1   \n",
       "...            ...                 ...               ...                  ...   \n",
       "27111            3                   5                 7                    2   \n",
       "27112            5                   0                 5                    1   \n",
       "27113            0                   0                 0                    0   \n",
       "27114            1                   5                 3                    7   \n",
       "27115            2                   1                 1                    0   \n",
       "\n",
       "       false_counts  pants_on_fire_counts  \\\n",
       "0                32                    19   \n",
       "1                11                     3   \n",
       "2                 1                     0   \n",
       "3                31                     9   \n",
       "4                 0                     0   \n",
       "...             ...                   ...   \n",
       "27111             4                     1   \n",
       "27112             0                     1   \n",
       "27113             1                     0   \n",
       "27114             3                     0   \n",
       "27115             0                     0   \n",
       "\n",
       "                                    context  \\\n",
       "0                              Hanover, N.H   \n",
       "1       a talk at a conservative think tank   \n",
       "2      an online video of an earlier speech   \n",
       "3                    Iowa and New Hampshire   \n",
       "4                                a web post   \n",
       "...                                     ...   \n",
       "27111                              a speech   \n",
       "27112                       a press release   \n",
       "27113              campaign press statement   \n",
       "27114          remarks at a news conference   \n",
       "27115               a letter to Portlanders   \n",
       "\n",
       "                                           justification  \n",
       "0      Romney has strong support for this . A recent ...  \n",
       "1      Why would Sanger try to destroy a race of peop...  \n",
       "2      Veterans are faring better than U.S. workers a...  \n",
       "3      But the Clinton campaign says she used her inf...  \n",
       "4      Webb said the U.S. has the highest incarcerati...  \n",
       "...                                                  ...  \n",
       "27111  Johnson opposes a raise to $15, the statement ...  \n",
       "27112  Both Democrats and Republicans have spun the n...  \n",
       "27113  There are some states that donât depend on com...  \n",
       "27114  Pritzker said \"Republican elected officials, a...  \n",
       "27115  Cities and counties for 85 percent of workers....  \n",
       "\n",
       "[27116 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_oversampling(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Given credit card dataset with 0 as the majority for 'Class' column. Returns credit card data with two classes\n",
    "    having the same shape, given raw data read from csv.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        The potentially imbalanced dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Oversampled dataset with equal number of fraudulent and legitimate data.\n",
    "    '''\n",
    "\n",
    "    majority = df[df['label'] == 1]\n",
    "    minority = df[df['label'] == 0]\n",
    "    n = majority.shape[0]\n",
    "    print(n)\n",
    "    minority = pd.DataFrame.sample(minority, n, replace=True, random_state=42)\n",
    "    return pd.concat([majority, minority], axis=0)\n",
    "\n",
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "print(train_df[train_df['label'] == 0].shape)\n",
    "print(train_df[train_df['label'] == 1].shape)\n",
    "print(train_df[train_df['label'] == 2].shape)\n",
    "print(train_df[train_df['label'] == 3].shape)\n",
    "print(train_df[train_df['label'] == 4].shape)\n",
    "print(train_df[train_df['label'] == 5].shape)\n",
    "print(\"Preprocess labels\")\n",
    "train_df['label'] = train_df['label'].apply(lambda x: 1 if x <= 3 else 0) # 0 (Real) for 3-5 and 1 (Fake) for 0-2\n",
    "print(train_df[train_df['label'] == 0].shape)\n",
    "print(train_df[train_df['label'] == 1].shape)\n",
    "train_df = random_oversampling(train_df)\n",
    "print(\"Oversampling\")\n",
    "print(train_df[train_df['label'] == 0].shape)\n",
    "print(train_df[train_df['label'] == 1].shape)\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "val_df = pd.read_csv(\"val.csv\")\n",
    "val_df['label'] = val_df['label'].apply(lambda x: 1 if x <= 3 else 0) # 0 (Real) for 3-5 and 1 (Fake) for 0-2\n",
    "val_df = random_oversampling(val_df) # We have to balance this too otherwise training yields really poor results\n",
    "val_df = val_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df['label'] = test_df['label'].apply(lambda x: 1 if x <= 3 else 0) # 0 (Real) for 3-5 and 1 (Fake) for 0-2\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_row(row):\n",
    "    combined_input = (\n",
    "        \"Subject: \" + str(row['subject'] or \"\") + \n",
    "        \"; Speaker: \" + str(row['speaker'] or \"\") + \n",
    "        \"; Speaker Description: \" + str(row['speaker_description'] or \"\") + \n",
    "        \"; State: \" + str(row['state_info'] or \"\") + \n",
    "        \"; Context: \" + str(row['context'] or \"\") + \n",
    "        \"; Statement: \" + str(row['statement'] or \"\")\n",
    "    )\n",
    "    return combined_input\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Subject: health care;polls and public opinion;...\n",
       "1        Subject: abortion; Speaker: herman cain; Speak...\n",
       "2        Subject: economy;military;veterans; Speaker: s...\n",
       "3        Subject: health care; Speaker: hillary clinton...\n",
       "4        Subject: criminal justice;crime; Speaker: jim ...\n",
       "                               ...                        \n",
       "27111    Subject: agriculture;economy;jobs;labor;govern...\n",
       "27112    Subject: energy;jobs; Speaker: tom graves; Spe...\n",
       "27113    Subject: environment;jobs;message machine 2012...\n",
       "27114    Subject: fake news;coronavirus; Speaker: jb pr...\n",
       "27115    Subject: education;pensions;unions;workers; Sp...\n",
       "Name: input, Length: 27116, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function row-wise and store tokenized output\n",
    "train_df[\"input\"] = train_df.apply(preprocess_row, axis=1)\n",
    "val_df[\"input\"] = val_df.apply(preprocess_row, axis=1)\n",
    "test_df[\"input\"] = test_df.apply(preprocess_row, axis=1)\n",
    "\n",
    "train_df[\"input\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27116\n",
      "27116\n"
     ]
    }
   ],
   "source": [
    "# For convenience\n",
    "# train_df = train_df.head(100)\n",
    "# val_df = val_df.head(100)\n",
    "# test_df = test_df.head(100)\n",
    "\n",
    "train_X, train_Y = train_df['input'], train_df['label']\n",
    "val_X, val_Y = val_df['input'], val_df['label']\n",
    "test_X, test_Y = test_df['input'], test_df['label']\n",
    "\n",
    "print(len(train_X))\n",
    "print(len(train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    1696\n",
       "0    1696\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Classifier(torch.nn.Module):\n",
    "    def __init__(self, seq_len):\n",
    "        super(GPT2Classifier,self).__init__()\n",
    "        self.trfLayer = GPT2Model.from_pretrained(\"gpt2\")\n",
    "        self.seq_len = seq_len\n",
    "        self.fc = torch.nn.Linear(in_features=seq_len * 768, out_features=2)\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        input_ids = X[:, :self.seq_len]\n",
    "        att_masks = X[:, self.seq_len:]\n",
    "        outputs, _ = self.trfLayer(input_ids=input_ids, attention_mask=att_masks, return_dict=False)\n",
    "        batch_size = outputs.shape[0]\n",
    "        outputs = outputs.view(batch_size, -1)\n",
    "        outputs2 = self.fc(outputs)\n",
    "        return outputs2\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class\n",
    "    Inputs: Strings of statements, context and a vector corresponding to the 6 counts from the original dataset\n",
    "    Outputs: Encoded tokenized vectors for statements, context and a vector corresponding to the 6 counts from the original dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, features, labels, tokenizer, max_length=1024):\n",
    "        self.inputs = features\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length # Maximum sequence length\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.inputs[idx]\n",
    "        encoded_news = self.tokenizer(x, padding='max_length', max_length=self.max_length, truncation=True, return_tensors=\"pt\")\n",
    "        # decoded_string = self.tokenizer.decode(encoded_news[\"input_ids\"][0], skip_special_tokens=True)\n",
    "        # print(decoded_string)\n",
    "        return encoded_news, self.labels[idx]\n",
    "    \n",
    "def load_model(path, s):\n",
    "    \"\"\"\n",
    "    Loads model from directory.\n",
    "    \"\"\"\n",
    "    model = GPT2Classifier(seq_len=s)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def train(m: GPT2Classifier, trainData, valData, lr, early_stop_tol):\n",
    "    max_epochs = 500\n",
    "    trainLoader = DataLoader(trainData, batch_size=16, shuffle=True)\n",
    "    valLoader = DataLoader(valData, batch_size=16, shuffle=True)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        m = m.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    did_not_improve_count = 0\n",
    "    best_val_score = 0\n",
    "    best_epoch = 0\n",
    "    best_state_dict = None\n",
    "    m.train()\n",
    "    \n",
    "    for epoch_num in range(max_epochs):\n",
    "        total_loss_train = 0\n",
    "        train_predictions = []\n",
    "        train_labels = []\n",
    "        for encoded_news, label in tqdm(trainLoader):\n",
    "            label = label.to(device)\n",
    "            news_mask = encoded_news['attention_mask'].squeeze(1).to(device)\n",
    "            news_input_id = encoded_news[\"input_ids\"].squeeze(1).to(device)  \n",
    "\n",
    "            X = torch.concat((news_input_id, news_mask), axis=-1)\n",
    "\n",
    "            output = m(X)\n",
    "\n",
    "            batch_loss = criterion(output, label)\n",
    "            total_loss_train += batch_loss.item()\n",
    "\n",
    "            # add original labels\n",
    "            train_labels += label.cpu().numpy().flatten().tolist()\n",
    "            train_predictions += output.argmax(dim=1).cpu().numpy().flatten().tolist()\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_loss_val = 0\n",
    "        val_predictions = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for encoded_news, label in valLoader:\n",
    "                label = label.to(device)\n",
    "                news_mask = encoded_news['attention_mask'].squeeze(1).to(device)\n",
    "                news_input_id = encoded_news[\"input_ids\"].squeeze(1).to(device)\n",
    "\n",
    "                X = torch.concat((news_input_id, news_mask), axis=-1)            \n",
    "\n",
    "                output = m(X)\n",
    "                    \n",
    "                batch_loss = criterion(output, label)\n",
    "                total_loss_val += batch_loss.item()\n",
    "                \n",
    "                val_labels += label.cpu().numpy().flatten().tolist()\n",
    "                val_predictions += output.argmax(dim=1).cpu().numpy().flatten().tolist()\n",
    "        \n",
    "        train_labels = np.array(train_labels)\n",
    "        train_predictions = np.array(train_predictions)\n",
    "        val_labels = np.array(val_labels)\n",
    "        val_predictions = np.array(val_predictions)\n",
    "        \n",
    "        train_r = recall_score(train_labels, train_predictions)\n",
    "        train_p = precision_score(train_labels, train_predictions)\n",
    "        train_f1 = f1_score(train_labels, train_predictions)\n",
    "        train_acc = accuracy_score(train_labels, train_predictions)\n",
    "\n",
    "        val_r = recall_score(val_labels, val_predictions)\n",
    "        val_p = precision_score(val_labels, val_predictions)\n",
    "        val_f1 = f1_score(val_labels, val_predictions)\n",
    "        val_acc = accuracy_score(val_labels, val_predictions)\n",
    "\n",
    "        if val_acc > (best_val_score + early_stop_tol): # We shouldn't be early stopping based on recall cos then the model will just overfit to positives only\n",
    "            best_val_score = val_acc\n",
    "            did_not_improve_count = 0\n",
    "            best_epoch = epoch_num\n",
    "            best_state_dict = copy.deepcopy(m.state_dict())\n",
    "            print(f\"Saving new best val acc {best_val_score}\")\n",
    "            torch.save(best_state_dict, f\"gpt2-lr{lr}-iter{best_epoch+1}-tol{early_stop_tol}.pt\")\n",
    "        else:\n",
    "            did_not_improve_count += 1\n",
    "\n",
    "        print(\n",
    "            f\"Epochs: {epoch_num + 1} | Train Loss {total_loss_train/len(trainData): .3f} \\\n",
    "    | Train R,P,Acc,F1 = {train_r: .3f}, {train_p: .3f}, {train_acc: .3f}, {train_f1: .3f} \\\n",
    "            | Val Loss: {total_loss_val / len(valData): .3f} \\\n",
    "    | Val R,P,Acc,F1 = {val_r: .3f}, {val_p: .3f}, {val_acc: .3f}, {val_f1: .3f}\") \n",
    "        \n",
    "        print(f\"Val True Labels 1={np.sum(val_labels == 1)}, 0={np.sum(val_labels == 0)}\")\n",
    "        print(f\"Val Predictions 1={np.sum(val_predictions == 1)}, 0={np.sum(val_predictions == 0)}\")\n",
    "             \n",
    "        if did_not_improve_count >= 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "s = 128\n",
    "hidden_size = 768\n",
    "val_tol = 0.01\n",
    "lr = 5e-6\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2Classifier(seq_len=s)\n",
    "trainData = NewsDataset(features=train_X, labels=train_Y, tokenizer=tokenizer, max_length=s)\n",
    "valData = NewsDataset(features=val_X, labels=val_Y, tokenizer=tokenizer, max_length=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 1695/1695 [07:43<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving new best val acc 0.5262382075471698\n",
      "Epochs: 1 | Train Loss  0.207     | Train R,P,Acc,F1 =  0.533,  0.509,  0.509,  0.520             | Val Loss:  0.071     | Val R,P,Acc,F1 =  0.780,  0.517,  0.526,  0.622\n",
      "Val True Labels 1=1696, 0=1696\n",
      "Val Predictions 1=2557, 0=835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 1695/1695 [07:43<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving new best val acc 0.5498231132075472\n",
      "Epochs: 2 | Train Loss  0.232     | Train R,P,Acc,F1 =  0.467,  0.526,  0.523,  0.494             | Val Loss:  0.131     | Val R,P,Acc,F1 =  0.750,  0.536,  0.550,  0.625\n",
      "Val True Labels 1=1696, 0=1696\n",
      "Val Predictions 1=2375, 0=1017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 1695/1695 [07:43<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving new best val acc 0.5943396226415094\n",
      "Epochs: 3 | Train Loss  0.188     | Train R,P,Acc,F1 =  0.608,  0.533,  0.538,  0.568             | Val Loss:  0.082     | Val R,P,Acc,F1 =  0.383,  0.664,  0.594,  0.485\n",
      "Val True Labels 1=1696, 0=1696\n",
      "Val Predictions 1=978, 0=2414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 1695/1695 [07:43<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss  0.135     | Train R,P,Acc,F1 =  0.528,  0.596,  0.585,  0.560             | Val Loss:  0.185     | Val R,P,Acc,F1 =  0.965,  0.508,  0.516,  0.666\n",
      "Val True Labels 1=1696, 0=1696\n",
      "Val Predictions 1=3220, 0=172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 1695/1695 [07:43<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving new best val acc 0.6238207547169812\n",
      "Epochs: 5 | Train Loss  0.115     | Train R,P,Acc,F1 =  0.687,  0.623,  0.635,  0.653             | Val Loss:  0.095     | Val R,P,Acc,F1 =  0.647,  0.618,  0.624,  0.632\n",
      "Val True Labels 1=1696, 0=1696\n",
      "Val Predictions 1=1776, 0=1616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 1695/1695 [07:42<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving new best val acc 0.6394457547169812\n",
      "Epochs: 6 | Train Loss  0.090     | Train R,P,Acc,F1 =  0.689,  0.712,  0.705,  0.700             | Val Loss:  0.133     | Val R,P,Acc,F1 =  0.439,  0.733,  0.639,  0.549\n",
      "Val True Labels 1=1696, 0=1696\n",
      "Val Predictions 1=1017, 0=2375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 1695/1695 [07:42<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 | Train Loss  0.075     | Train R,P,Acc,F1 =  0.746,  0.752,  0.750,  0.749             | Val Loss:  0.131     | Val R,P,Acc,F1 =  0.445,  0.725,  0.638,  0.552\n",
      "Val True Labels 1=1696, 0=1696\n",
      "Val Predictions 1=1041, 0=2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 1695/1695 [07:42<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 | Train Loss  0.066     | Train R,P,Acc,F1 =  0.767,  0.780,  0.775,  0.773             | Val Loss:  0.162     | Val R,P,Acc,F1 =  0.491,  0.688,  0.634,  0.573\n",
      "Val True Labels 1=1696, 0=1696\n",
      "Val Predictions 1=1210, 0=2182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 1695/1695 [07:42<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 | Train Loss  0.054     | Train R,P,Acc,F1 =  0.816,  0.815,  0.815,  0.816             | Val Loss:  0.163     | Val R,P,Acc,F1 =  0.577,  0.644,  0.629,  0.608\n",
      "Val True Labels 1=1696, 0=1696\n",
      "Val Predictions 1=1519, 0=1873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 1695/1695 [07:45<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 | Train Loss  0.044     | Train R,P,Acc,F1 =  0.852,  0.850,  0.851,  0.851             | Val Loss:  0.209     | Val R,P,Acc,F1 =  0.687,  0.615,  0.628,  0.649\n",
      "Val True Labels 1=1696, 0=1696\n",
      "Val Predictions 1=1895, 0=1497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 1695/1695 [07:58<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 11 | Train Loss  0.042     | Train R,P,Acc,F1 =  0.863,  0.866,  0.864,  0.864             | Val Loss:  0.309     | Val R,P,Acc,F1 =  0.825,  0.565,  0.595,  0.671\n",
      "Val True Labels 1=1696, 0=1696\n",
      "Val Predictions 1=2477, 0=915\n"
     ]
    }
   ],
   "source": [
    "train(m=model, trainData=trainData, valData=valData, lr=lr, early_stop_tol=val_tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2296\n",
      "Test Accuracy:  0.586, Recall:  0.506, Precision  0.884, Acc:  0.586 F1:  0.643\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, testData):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    testLoader = DataLoader(testData, batch_size=16, shuffle=True)\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for encoded_news, label in testLoader:\n",
    "            label = label.to(device)\n",
    "            news_mask = encoded_news['attention_mask'].squeeze(1).to(device)\n",
    "            news_input_id = encoded_news['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            X = torch.cat((news_input_id, news_mask), dim=-1)\n",
    "            output = model(X)\n",
    "                    \n",
    "            # add original labels\n",
    "            true_labels += label.cpu().numpy().flatten().tolist()\n",
    "            predictions += output.argmax(dim=1).cpu().numpy().flatten().tolist()\n",
    "\n",
    "    r_score = recall_score(true_labels, predictions)\n",
    "    p_score = precision_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    test_acc = accuracy_score(true_labels, predictions)\n",
    "    print(f'Test Accuracy: {test_acc: .3f}, Recall: {r_score: .3f}, Precision {p_score: .3f}, Acc: {test_acc: .3f} F1: {f1: .3f}')\n",
    "\n",
    "testData = NewsDataset(features=test_X, labels=test_Y, tokenizer=tokenizer, max_length=s)\n",
    "print(len(testData))\n",
    "gpt2Trf = load_model(\"./gpt2-lr5e-06-iter6-tol0.01.pt\", s=s)\n",
    "\n",
    "evaluate(gpt2Trf, testData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS3264",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
