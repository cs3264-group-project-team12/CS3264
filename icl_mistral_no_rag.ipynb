{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T05:24:19.865845Z",
     "iopub.status.busy": "2025-03-29T05:24:19.865514Z",
     "iopub.status.idle": "2025-03-29T05:24:27.995841Z",
     "shell.execute_reply": "2025-03-29T05:24:27.994873Z",
     "shell.execute_reply.started": "2025-03-29T05:24:19.865786Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\n",
      "Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl (76.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.4\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "import datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T05:24:35.348579Z",
     "iopub.status.busy": "2025-03-29T05:24:35.348286Z",
     "iopub.status.idle": "2025-03-29T05:24:35.352597Z",
     "shell.execute_reply": "2025-03-29T05:24:35.351704Z",
     "shell.execute_reply.started": "2025-03-29T05:24:35.348555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACE_TOKEN\"] = \"your_token\"\n",
    "login(os.environ[\"HUGGINGFACE_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T13:19:16.028562Z",
     "iopub.status.busy": "2025-03-29T13:19:16.028268Z",
     "iopub.status.idle": "2025-03-29T13:19:30.309082Z",
     "shell.execute_reply": "2025-03-29T13:19:30.308049Z",
     "shell.execute_reply.started": "2025-03-29T13:19:16.028537Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d1f9ecf5034660adf64e8cea9945da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.87k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e16694166f493eb51826df62213fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.csv:   0%|          | 0.00/19.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b16bb8ade644628ea919c4bc3156e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid.csv:   0%|          | 0.00/2.38M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f23beadccba4fd78ad93594cde38c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.csv:   0%|          | 0.00/2.38M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3027e913437d41158b4b272264349e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/18369 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6365c4ae5eb3479a87363faf72f01bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2297 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a63310584bf48cb87d6bbdb703b43d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = \"chengxuphd/liar2\"\n",
    "dataset = datasets.load_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T13:19:38.660356Z",
     "iopub.status.busy": "2025-03-29T13:19:38.660002Z",
     "iopub.status.idle": "2025-03-29T13:19:38.664828Z",
     "shell.execute_reply": "2025-03-29T13:19:38.663824Z",
     "shell.execute_reply.started": "2025-03-29T13:19:38.660319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert labels: {0, 1, 2, 3} -> 1, {4, 5} -> 0\n",
    "def convert_labels(data):\n",
    "    if data[\"label\"] in [0, 1, 2, 3]:\n",
    "        data[\"label\"] = 1\n",
    "    else:\n",
    "        data[\"label\"] = 0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T13:19:42.668494Z",
     "iopub.status.busy": "2025-03-29T13:19:42.668122Z",
     "iopub.status.idle": "2025-03-29T13:19:47.372979Z",
     "shell.execute_reply": "2025-03-29T13:19:47.371967Z",
     "shell.execute_reply.started": "2025-03-29T13:19:42.668464Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad18a9f660364c50ab3ea8ff10457370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18369 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87353d28891439986ea6812570e8f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2297 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd3d8a0f4e14e18a1c3182989535d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(convert_labels)\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-29T05:25:02.927822Z",
     "iopub.status.busy": "2025-03-29T05:25:02.927444Z",
     "iopub.status.idle": "2025-03-29T05:27:14.731218Z",
     "shell.execute_reply": "2025-03-29T05:27:14.730053Z",
     "shell.execute_reply.started": "2025-03-29T05:25:02.927766Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9a835afa7c49ac986e0a0159f7dd59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704e03d372c642e6a6864323438ee60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5ffe878749464894fabb132d662a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd0d61f76a54a60b3c1077b8415aafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b6e9e7ed6c45d990fffba2c7ab920c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635bc734d23e47da90f365842afcd3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd33335be25245e79f6575d8a36cba3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debbaaae03fb4eb19f57b5782abdcd31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cef0afe1f04f14b2adbd0bdcf0443b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571467d78e5441478c461fa28721a583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99df1cba75ea409fb021e6fdf608ec35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b106acf9d844efa4db11d1e287a2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e45caae823c4a989cc94b0db50720bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", quantization_config=quantization_config, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T06:15:09.282461Z",
     "iopub.status.busy": "2025-03-29T06:15:09.282151Z",
     "iopub.status.idle": "2025-03-29T06:15:09.289168Z",
     "shell.execute_reply": "2025-03-29T06:15:09.288172Z",
     "shell.execute_reply.started": "2025-03-29T06:15:09.282437Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Zero-shot prompt template\n",
    "def format_chat_prompt_v1(claim):\n",
    "    \"\"\"Formats input using the chat template for better responses (zero-shot).\"\"\"\n",
    "    user_input = f\"\"\"Classify the following claim as FAKE or REAL, and highlight only the top five keywords contributing to the classification.\n",
    "    \n",
    "    Focus only on linguistic features (tone, exaggeration, emotional appeal) and do NOT use any factual knowledge.\n",
    "    \n",
    "    Claim: \"{claim}\"\n",
    "    \n",
    "    Output the result in the following structured format:\n",
    "    \n",
    "    Classification: (FAKE or REAL)\n",
    "    \n",
    "    Keywords: [list of ONLY five important words]\n",
    "    \n",
    "    Linguistic Reasoning: (Explain based on language features such as exaggeration, strong emotions, vagueness, etc.)\"\"\"\n",
    "\n",
    "    chat_prompt = tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI that detects fake news using linguistic analysis, focusing on tone and word choice, without relying on factual knowledge.\"},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ],\n",
    "        tokenize=False,  # Keep raw string for LLM\n",
    "        add_generation_prompt=True,  # Adds assistant's turn automatically\n",
    "    )\n",
    "    return chat_prompt\n",
    "\n",
    "# Few-shot prompt template\n",
    "def format_chat_prompt_v2(claim):\n",
    "    \"\"\"Formats input using the chat template for better responses with few-shot examples.\"\"\"\n",
    "\n",
    "    chat_prompt = tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI that classifies a piece of text as FAKE or REAL, using linguistic analysis, focusing on tone and word choice, without relying on factual knowledge.\"},\n",
    "            \n",
    "            # Example 1 (FAKE)\n",
    "            {\"role\": \"user\", \"content\": \"\"\"Classify the following claim as FAKE or REAL, and highlight only the top five keywords contributing to the classification.\n",
    "\n",
    "            Do NOT give any classification other than FAKE or REAL.\n",
    "            \n",
    "            Focus only on linguistic features (tone, exaggeration, emotional appeal) and do NOT use any factual knowledge.\n",
    "            \n",
    "            Claim: \"President Obama used government funds to pay for his personal vacations for the next 20 years and Trump sent him a bill.\"\n",
    "            \n",
    "            Output the result in the following structured format:\n",
    "    \n",
    "            Classification: (FAKE or REAL)\n",
    "    \n",
    "            Keywords: [list of ONLY five important words]\n",
    "    \n",
    "            Linguistic Reasoning: (Explain based on language features such as exaggeration, strong emotions, vagueness, etc.)\"\"\"},\n",
    "            \n",
    "            {\"role\": \"assistant\", \"content\": \"\"\"Classification: FAKE\n",
    "            \n",
    "            Keywords: \"government funds\", \"personal vacations\", \"20 years\", \"Trump\", \"bill\"\n",
    "            \n",
    "            Linguistic Reasoning: The claim uses exaggeration, sensational language, and vague accusations (e.g., \"20 years\", \"government funds\") to create drama and suspicion without evidence.\"\"\"},\n",
    "\n",
    "            # Example 2 (REAL)\n",
    "            {\"role\": \"user\", \"content\": \"\"\"Classify the following claim as FAKE or REAL, and highlight only the top five keywords contributing to the classification.\n",
    "            \n",
    "            Do NOT give any classification other than FAKE or REAL.\n",
    "            \n",
    "            Focus only on linguistic features (tone, exaggeration, emotional appeal) and do NOT use any factual knowledge.\n",
    "            \n",
    "            Claim: \"Despite having their budget increased by over 40 percent since 2009, pending claims for benefits with the Department of Veterans Affairs have increased from 391,000 to 890,000 under the Obama Administration.\"\n",
    "            \n",
    "            Output the result in the following structured format:\n",
    "    \n",
    "            Classification: (FAKE or REAL)\n",
    "    \n",
    "            Keywords: [list of ONLY five important words]\n",
    "    \n",
    "            Linguistic Reasoning: (Explain based on language features such as exaggeration, strong emotions, vagueness, etc.)\"\"\"},\n",
    "            \n",
    "            {\"role\": \"assistant\", \"content\": \"\"\"Classification: REAL\n",
    "            \n",
    "            Keywords: \"budget\", \"40 percent\", \"pending claims\", \"Department of Veterans Affairs\", \"Obama Administration\"\n",
    "            \n",
    "            Linguistic Reasoning: The claim presents specific figures, neutral wording, and clear attribution, making it sound objective and fact-based rather than emotional or exaggerated.\"\"\"},\n",
    "\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"Classify the following claim as FAKE or REAL, and highlight only the top five keywords contributing to the classification.\n",
    "            \n",
    "            Do NOT give any classification other than FAKE or REAL.\n",
    "            \n",
    "            Focus only on linguistic features (tone, exaggeration, emotional appeal) and do NOT use any factual knowledge.\n",
    "            \n",
    "            Claim: \"{claim}\"\n",
    "            \n",
    "            Output the result in the following structured format:\n",
    "    \n",
    "            Classification: (FAKE or REAL)\n",
    "    \n",
    "            Keywords: [list of ONLY five important words]\n",
    "    \n",
    "            Linguistic Reasoning: (Explain based on language features such as exaggeration, strong emotions, vagueness, etc.)\"\"\"}\n",
    "        ],\n",
    "        tokenize=False,  # Keep raw string for LLM\n",
    "        add_generation_prompt=True,  # Adds assistant's turn automatically\n",
    "    )\n",
    "    \n",
    "    return chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T05:28:56.179781Z",
     "iopub.status.busy": "2025-03-29T05:28:56.179424Z",
     "iopub.status.idle": "2025-03-29T05:28:56.186130Z",
     "shell.execute_reply": "2025-03-29T05:28:56.185225Z",
     "shell.execute_reply.started": "2025-03-29T05:28:56.179732Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Extract classification, keywords, and reasoning from model output\n",
    "def extract_prediction(response):\n",
    "    # Extract classification (FAKE or REAL)\n",
    "    classification_match = re.search(r'Classification:\\s*(FAKE|REAL)', response)\n",
    "    classification = classification_match.group(1) if classification_match else \"UNKNOWN\"\n",
    "\n",
    "    # Extract keywords as a list\n",
    "    keywords_match = re.search(r'Keywords:\\s*(.*)', response)\n",
    "    \n",
    "    if keywords_match:\n",
    "        keywords_text = keywords_match.group(1).strip()\n",
    "        \n",
    "        # Split by commas and remove any stray quotes/spaces\n",
    "        keywords = [kw.strip().strip('\"').strip(\"'\") for kw in keywords_text.split(\",\")]\n",
    "    else:\n",
    "        keywords = []\n",
    "\n",
    "    # Extract linguistic reasoning\n",
    "    reasoning_match = re.search(r'Linguistic Reasoning:\\s*(.*)', response, re.DOTALL)\n",
    "    reasoning = reasoning_match.group(1).strip() if reasoning_match else \"No reasoning provided.\"\n",
    "    \n",
    "    return classification, keywords, reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T05:29:01.106231Z",
     "iopub.status.busy": "2025-03-29T05:29:01.105902Z",
     "iopub.status.idle": "2025-03-29T05:29:01.114531Z",
     "shell.execute_reply": "2025-03-29T05:29:01.113689Z",
     "shell.execute_reply.started": "2025-03-29T05:29:01.106202Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Perform evaluation to extract results from test dataset into a .csv file\n",
    "def evaluate(shot=0):\n",
    "    results = []\n",
    "    unknown_count = 0\n",
    "    \n",
    "    for sample in test_dataset:\n",
    "        claim = sample[\"statement\"]\n",
    "        true_label = sample[\"label\"]\n",
    "    \n",
    "        # Format prompt using chat template\n",
    "        if prompt_type == 0:\n",
    "            formatted_prompt = format_chat_prompt_v1(claim)\n",
    "        else:\n",
    "            formatted_prompt = format_chat_prompt_v2(claim)\n",
    "    \n",
    "        # Tokenize and generate response\n",
    "        inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        output_tokens = model.generate(**inputs, max_new_tokens=150)\n",
    "        model_response = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "    \n",
    "        cleaned_response = model_response.split(\"[/INST]\")[-1].strip()\n",
    "    \n",
    "        # Extract structured outputs\n",
    "        predicted_label, keywords, reasoning = extract_prediction(cleaned_response)\n",
    "    \n",
    "        # Convert predicted label to binary (FAKE=1, REAL=0)\n",
    "        if predicted_label == \"FAKE\":\n",
    "            pred_label = 1\n",
    "        elif predicted_label == \"REAL\":\n",
    "            pred_label = 0\n",
    "        else: # Unknown label predicted\n",
    "            print(predicted_label)\n",
    "            pred_label = -1\n",
    "            unknown_count += 1\n",
    "        \n",
    "        results.append({\n",
    "                \"Claim\": claim,\n",
    "                \"Prediction\": pred_label,\n",
    "                \"Keywords\": \", \".join(keywords),\n",
    "                \"Linguistic Reasoning\": reasoning,\n",
    "                \"True Label\": true_label\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(\"results_zeroshot.csv\", index=False)\n",
    "    print(f\"Number of test instances where model outputs an unknown classification: {unknown_count}\")\n",
    "    print(f\"% of test instances where model outputs either FAKE or REAL: {(len(test_dataset) - unknown_count) / len(test_dataset)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "evaluate(shot=0) # zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "df = pd.read_csv('results_zeroshot.csv')\n",
    "\n",
    "# Filter out rows with Prediction == -1\n",
    "df = df[df[\"Prediction\"] != -1]\n",
    "\n",
    "df_class_0 = df[df[\"True Label\"] == 0]\n",
    "df_class_1 = df[df[\"True Label\"] == 1]\n",
    "\n",
    "minority_class_size = min(len(df_class_0), len(df_class_1))\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1': []\n",
    "}\n",
    "\n",
    "# Run the sampling and evaluation 5 times\n",
    "for _ in range(5):\n",
    "    if len(df_class_0) < len(df_class_1):\n",
    "        sampled_majority = df_class_1.sample(n=minority_class_size, random_state=np.random.randint(0, 10000))\n",
    "        balanced_df = pd.concat([df_class_0, sampled_majority])\n",
    "    else:\n",
    "        sampled_majority = df_class_0.sample(n=minority_class_size, random_state=np.random.randint(0, 10000))\n",
    "        balanced_df = pd.concat([df_class_1, sampled_majority])\n",
    "\n",
    "    # Shuffle the balanced dataset\n",
    "    balanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    y_true = balanced_df[\"True Label\"]\n",
    "    y_pred = balanced_df[\"Prediction\"]\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics['accuracy'].append(accuracy_score(y_true, y_pred))\n",
    "    metrics['precision'].append(precision_score(y_true, y_pred))\n",
    "    metrics['recall'].append(recall_score(y_true, y_pred))\n",
    "    metrics['f1'].append(f1_score(y_true, y_pred))\n",
    "\n",
    "# Compute and print average metrics\n",
    "avg_metrics = {k: np.mean(v) for k, v in metrics.items()}\n",
    "print(\"Averaged Metrics over 5 runs:\")\n",
    "for metric, score in avg_metrics.items():\n",
    "    print(f\"{metric.capitalize()}: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T09:35:04.069701Z",
     "iopub.status.busy": "2025-03-27T09:35:04.069390Z",
     "iopub.status.idle": "2025-03-27T09:36:24.078945Z",
     "shell.execute_reply": "2025-03-27T09:36:24.078209Z",
     "shell.execute_reply.started": "2025-03-27T09:35:04.069680Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim:\n",
      "90 percent of Americans \"support universal background checks\" for gun purchases.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: FAKE\n",
      "\n",
      "Keywords: \"90 percent of Americans\", \"support\", \"universal background checks\"\n",
      "\n",
      "Linguistic Reasoning: The use of the quantifier \"90 percent\" is an exaggeration, as it is unlikely that such a high percentage of Americans would support a single policy position. The word \"support\" is vague and can be interpreted in different ways. The term \"universal background checks\" is emotionally charged and can evoke strong reactions from different groups, making the statement more likely to be a subject of debate rather than a fact.\n",
      "True Label:\n",
      "1\n",
      "('FAKE', ['90 percent of Americans', 'support', 'universal background checks'], 'The use of the quantifier \"90 percent\" is an exaggeration, as it is unlikely that such a high percentage of Americans would support a single policy position. The word \"support\" is vague and can be interpreted in different ways. The term \"universal background checks\" is emotionally charged and can evoke strong reactions from different groups, making the statement more likely to be a subject of debate rather than a fact.')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "Last year was one of the deadliest years ever for law enforcement officers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: REAL\n",
      "\n",
      "Keywords: deadliest years, law enforcement officers\n",
      "\n",
      "Linguistic Reasoning: The claim uses the words \"deadliest years\" which is an objective and quantifiable term. The use of the word \"ever\" indicates a superlative degree, but it does not necessarily imply exaggeration as it is a common way to describe extreme events. The claim does not contain any strong emotions or vagueness that would suggest it is fake.\n",
      "True Label:\n",
      "0\n",
      "('REAL', ['deadliest years', 'law enforcement officers'], 'The claim uses the words \"deadliest years\" which is an objective and quantifiable term. The use of the word \"ever\" indicates a superlative degree, but it does not necessarily imply exaggeration as it is a common way to describe extreme events. The claim does not contain any strong emotions or vagueness that would suggest it is fake.')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "Bernie Sanders's plan is \"to raise your taxes to 90 percent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: FAKE\n",
      "\n",
      "Keywords: Bernie Sanders, plan, raise, taxes, 90 percent\n",
      "\n",
      "Linguistic Reasoning: The claim contains an extreme exaggeration of the tax rate proposed by Bernie Sanders, which is not factually correct. The use of the number 90 percent is highly emotive and sensational, making it unlikely that this statement is a genuine representation of Bernie Sanders's actual policy.\n",
      "True Label:\n",
      "0\n",
      "('FAKE', ['Bernie Sanders', 'plan', 'raise', 'taxes', '90 percent'], \"The claim contains an extreme exaggeration of the tax rate proposed by Bernie Sanders, which is not factually correct. The use of the number 90 percent is highly emotive and sensational, making it unlikely that this statement is a genuine representation of Bernie Sanders's actual policy.\")\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "Voter ID is supported by an overwhelming majority of NYers, from all across the state, walks of life, & political parties.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: FAKE\n",
      "\n",
      "Keywords: overwhelming majority, NYers, all across, walks of life, political parties\n",
      "\n",
      "Linguistic Reasoning: The use of the term \"overwhelming majority\" is an exaggeration, implying a level of support that is unlikely to be true for such a diverse and politically complex state as New York. The phrase \"all across\" is vague and implies a level of geographical reach that is not supported by the provided information. The inclusion of \"walks of life\" and \"political parties\" is an emotional appeal, attempting to create a sense of inclusivity and unity, but does not provide any concrete evidence to support the claim.\n",
      "True Label:\n",
      "1\n",
      "('FAKE', ['overwhelming majority', 'NYers', 'all across', 'walks of life', 'political parties'], 'The use of the term \"overwhelming majority\" is an exaggeration, implying a level of support that is unlikely to be true for such a diverse and politically complex state as New York. The phrase \"all across\" is vague and implies a level of geographical reach that is not supported by the provided information. The inclusion of \"walks of life\" and \"political parties\" is an emotional appeal, attempting to create a sense of inclusivity and unity, but does not provide any concrete evidence to support the claim.')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "Says Barack Obama \"robbed Medicare (of) $716 billion to pay for ... Obamacare.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: FAKE\n",
      "\n",
      "Keywords: \"robbed\", \"Medicare\", \"Obamacare\", \"paid for\", \"$716 billion\"\n",
      "\n",
      "Linguistic Reasoning: The use of the word \"robbed\" is an exaggeration and emotionally charged language, implying an illegal or unethical act. The statement is vague about how the money was \"robbed\" from Medicare and used to pay for Obamacare. The specific amount mentioned, \"$716 billion,\" adds to the exaggeration and may be intended to evoke a strong emotional response. The statement does not provide any context or evidence to support the claim, making it unreliable based\n",
      "True Label:\n",
      "0\n",
      "('FAKE', ['robbed', 'Medicare', 'Obamacare', 'paid for', '$716 billion'], 'The use of the word \"robbed\" is an exaggeration and emotionally charged language, implying an illegal or unethical act. The statement is vague about how the money was \"robbed\" from Medicare and used to pay for Obamacare. The specific amount mentioned, \"$716 billion,\" adds to the exaggeration and may be intended to evoke a strong emotional response. The statement does not provide any context or evidence to support the claim, making it unreliable based')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "Video says COVID-19 vaccines are \"weapons of mass destruction\" that \"could wipe out the human race.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: FAKE\n",
      "\n",
      "Keywords: COVID-19 vaccines, weapons of mass destruction, could wipe out the human race\n",
      "\n",
      "Linguistic Reasoning: The claim contains strong emotional language and exaggeration. The use of the term \"weapons of mass destruction\" is an extreme and alarmist statement, which is not a common or factual way to describe COVID-19 vaccines. The phrase \"could wipe out the human race\" is also an exaggeration and a fear-mongering statement, which is not based on factual evidence. These linguistic features suggest that the claim is likely to be fake news.\n",
      "True Label:\n",
      "0\n",
      "('FAKE', ['COVID-19 vaccines', 'weapons of mass destruction', 'could wipe out the human race'], 'The claim contains strong emotional language and exaggeration. The use of the term \"weapons of mass destruction\" is an extreme and alarmist statement, which is not a common or factual way to describe COVID-19 vaccines. The phrase \"could wipe out the human race\" is also an exaggeration and a fear-mongering statement, which is not based on factual evidence. These linguistic features suggest that the claim is likely to be fake news.')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "Says Jeff Reardon cut elementary school music classes, art instruction, teaching positions, basketball and volleyball programs, and he voted to raise school lunch prices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: REAL\n",
      "\n",
      "Keywords: Jeff Reardon, cut, elementary school, music classes, art instruction\n",
      "\n",
      "Linguistic Reasoning: The claim uses specific names and actions, which adds to its credibility. The use of the verb \"cut\" implies a clear and definitive action, and the mention of specific programs such as music classes and art instruction further supports the claim's authenticity. The tone of the claim is factual and straightforward, with no obvious exaggeration or emotional appeal.\n",
      "True Label:\n",
      "0\n",
      "('REAL', ['Jeff Reardon', 'cut', 'elementary school', 'music classes', 'art instruction'], 'The claim uses specific names and actions, which adds to its credibility. The use of the verb \"cut\" implies a clear and definitive action, and the mention of specific programs such as music classes and art instruction further supports the claim\\'s authenticity. The tone of the claim is factual and straightforward, with no obvious exaggeration or emotional appeal.')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "One in three women is sexually assaulted on the dangerous journey north.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: FAKE\n",
      "\n",
      "Keywords: one in three, women, dangerous journey, north, sexually assaulted\n",
      "\n",
      "Linguistic Reasoning: The statement \"One in three women is sexually assaulted on the dangerous journey north\" is an exaggeration. The use of the phrase \"one in three\" is a statistical claim that implies a high prevalence, which is likely to evoke strong emotions and concern. However, without specific facts or data, this claim is vague and unverifiable. The words \"dangerous journey north\" also contribute to the emotional appeal and sense of danger, further increasing the likelihood of the statement being perceived as sensational or exaggerated.\n",
      "True Label:\n",
      "1\n",
      "('FAKE', ['one in three', 'women', 'dangerous journey', 'north', 'sexually assaulted'], 'The statement \"One in three women is sexually assaulted on the dangerous journey north\" is an exaggeration. The use of the phrase \"one in three\" is a statistical claim that implies a high prevalence, which is likely to evoke strong emotions and concern. However, without specific facts or data, this claim is vague and unverifiable. The words \"dangerous journey north\" also contribute to the emotional appeal and sense of danger, further increasing the likelihood of the statement being perceived as sensational or exaggerated.')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "It's actually the safest time to fly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: REAL\n",
      "\n",
      "Keywords: it, actually, safest, time, fly\n",
      "\n",
      "Linguistic Reasoning: The claim is stated in a matter-of-fact tone with no clear signs of exaggeration or emotional appeal. The use of the words \"it's actually\" implies a correction or contradiction of a common belief, which could be an attempt to downplay the risk of flying. However, without additional context, it's important to note that this classification is based solely on linguistic features and does not take into account any factual information or the specific meaning of the word \"safest.\"\n",
      "True Label:\n",
      "0\n",
      "('REAL', ['it', 'actually', 'safest', 'time', 'fly'], 'The claim is stated in a matter-of-fact tone with no clear signs of exaggeration or emotional appeal. The use of the words \"it\\'s actually\" implies a correction or contradiction of a common belief, which could be an attempt to downplay the risk of flying. However, without additional context, it\\'s important to note that this classification is based solely on linguistic features and does not take into account any factual information or the specific meaning of the word \"safest.\"')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "We know dangerous criminals can slip through immigration at airports just like ours. Yet Joe Donnelly stood right here with the radical left against all efforts to secure our most vulnerable entry points.\n",
      "Model Response:\n",
      "Classification: FAKE\n",
      "\n",
      "Keywords: dangerous criminals, slip through, immigration, airports, vulnerable entry points\n",
      "\n",
      "Linguistic Reasoning: The claim uses strong emotional language and vague terms to create a sense of fear and urgency. The use of the words \"dangerous criminals\" and \"slip through\" implies a significant threat, which may not be based on factual evidence. The phrase \"yet Joe Donnelly stood right here with the radical left\" is an attempt to create a clear dichotomy between \"us\" (implicitly the speaker and those who agree with them) and \"the radical left,\" which may be an exaggerated and polarizing description of political opposition.\n",
      "True Label:\n",
      "0\n",
      "('FAKE', ['dangerous criminals', 'slip through', 'immigration', 'airports', 'vulnerable entry points'], 'The claim uses strong emotional language and vague terms to create a sense of fear and urgency. The use of the words \"dangerous criminals\" and \"slip through\" implies a significant threat, which may not be based on factual evidence. The phrase \"yet Joe Donnelly stood right here with the radical left\" is an attempt to create a clear dichotomy between \"us\" (implicitly the speaker and those who agree with them) and \"the radical left,\" which may be an exaggerated and polarizing description of political opposition.')\n",
      "\n",
      "#########################\n"
     ]
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "#     train_claim = dataset[\"train\"][\"statement\"][i]\n",
    "#     train_label = dataset[\"train\"][\"label\"][i]\n",
    "#     print(f\"Claim:\\n{train_claim}\")\n",
    "#     formatted_prompt = format_chat_prompt_v1(train_claim)\n",
    "    \n",
    "#     inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "#     output_tokens = model.generate(**inputs, max_new_tokens=150)\n",
    "#     model_response = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "    \n",
    "#     cleaned_response = model_response.split(\"[/INST]\")[-1].strip()\n",
    "#     print(f\"Model Response:\\n{cleaned_response}\")\n",
    "#     print(f\"True Label:\\n{train_label}\")\n",
    "\n",
    "#     print(extract_prediction(cleaned_response))\n",
    "#     print(\"\\n#########################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T06:15:25.338575Z",
     "iopub.status.busy": "2025-03-29T06:15:25.338273Z",
     "iopub.status.idle": "2025-03-29T06:16:28.992283Z",
     "shell.execute_reply": "2025-03-29T06:16:28.991461Z",
     "shell.execute_reply.started": "2025-03-29T06:15:25.338551Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim:\n",
      "90 percent of Americans \"support universal background checks\" for gun purchases.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: FAKE\n",
      "\n",
      "Keywords: \"90 percent\", \"Americans\", \"support\", \"universal background checks\", \"gun purchases\"\n",
      "\n",
      "Linguistic Reasoning: The claim uses a high percentage figure to create a strong emotional appeal and exaggeration, which is not supported by any factual evidence.\n",
      "True Label:\n",
      "0\n",
      "('FAKE', ['90 percent', 'Americans', 'support', 'universal background checks', 'gun purchases'], 'The claim uses a high percentage figure to create a strong emotional appeal and exaggeration, which is not supported by any factual evidence.')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "Last year was one of the deadliest years ever for law enforcement officers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: REAL\n",
      "\n",
      "Keywords: \"deadliest years\", \"law enforcement officers\", \"last year\"\n",
      "\n",
      "Linguistic Reasoning: The claim uses strong language to convey a sense of urgency and importance, but it is not inherently exaggerated or emotionally charged. The use of the term \"deadliest years\" implies a comparison to previous years, which adds specificity to the claim.\n",
      "True Label:\n",
      "1\n",
      "('REAL', ['deadliest years', 'law enforcement officers', 'last year'], 'The claim uses strong language to convey a sense of urgency and importance, but it is not inherently exaggerated or emotionally charged. The use of the term \"deadliest years\" implies a comparison to previous years, which adds specificity to the claim.')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "Bernie Sanders's plan is \"to raise your taxes to 90 percent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: FAKE\n",
      "\n",
      "Keywords: \"Bernie Sanders's plan\", \"raise your taxes\", \"90 percent\"\n",
      "\n",
      "Linguistic Reasoning: The claim uses exaggeration and strong emotional language to create a sensational effect, which is not supported by factual evidence. In reality, Bernie Sanders has never proposed a tax rate of 90 percent.\n",
      "True Label:\n",
      "1\n",
      "('FAKE', [\"Bernie Sanders's plan\", 'raise your taxes', '90 percent'], 'The claim uses exaggeration and strong emotional language to create a sensational effect, which is not supported by factual evidence. In reality, Bernie Sanders has never proposed a tax rate of 90 percent.')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "Voter ID is supported by an overwhelming majority of NYers, from all across the state, walks of life, & political parties.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: FAKE\n",
      "\n",
      "Keywords: \"overwhelming majority\", \"NYers\", \"across the state\", \"walks of life\", \"political parties\"\n",
      "\n",
      "Linguistic Reasoning: The claim uses exaggeration and vague language to create a sense of broad support for Voter ID without providing any specific evidence or data to back up the claim.\n",
      "True Label:\n",
      "0\n",
      "('FAKE', ['overwhelming majority', 'NYers', 'across the state', 'walks of life', 'political parties'], 'The claim uses exaggeration and vague language to create a sense of broad support for Voter ID without providing any specific evidence or data to back up the claim.')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "Says Barack Obama \"robbed Medicare (of) $716 billion to pay for ... Obamacare.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: FAKE\n",
      "\n",
      "Keywords: \"robbed\", \"Medicare\", \"$716 billion\", \"Obamacare\"\n",
      "\n",
      "Linguistic Reasoning: The claim uses strong, emotionally charged language (\"robbed\") and vague accusations (\"pay for ... Obamacare\") without providing specific evidence or clear attribution, making it sound sensational and potentially misleading.\n",
      "True Label:\n",
      "1\n",
      "('FAKE', ['robbed', 'Medicare', '$716 billion', 'Obamacare'], 'The claim uses strong, emotionally charged language (\"robbed\") and vague accusations (\"pay for ... Obamacare\") without providing specific evidence or clear attribution, making it sound sensational and potentially misleading.')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "Video says COVID-19 vaccines are \"weapons of mass destruction\" that \"could wipe out the human race.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: FAKE\n",
      "\n",
      "Keywords: \"weapons of mass destruction\", \"could wipe out the human race\", \"vaccines\", \"video\"\n",
      "\n",
      "Linguistic Reasoning: The claim uses strong emotional language and exaggeration to create a sense of fear and urgency, which is not supported by factual evidence. The use of the term \"weapons of mass destruction\" is particularly alarming and not based on reality.\n",
      "True Label:\n",
      "1\n",
      "('FAKE', ['weapons of mass destruction', 'could wipe out the human race', 'vaccines', 'video'], 'The claim uses strong emotional language and exaggeration to create a sense of fear and urgency, which is not supported by factual evidence. The use of the term \"weapons of mass destruction\" is particularly alarming and not based on reality.')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "Says Jeff Reardon cut elementary school music classes, art instruction, teaching positions, basketball and volleyball programs, and he voted to raise school lunch prices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: FAKE\n",
      "            \n",
      "            Keywords: \"Says\", \"Jeff Reardon\", \"cut\", \"elementary school\", \"music classes\"\n",
      "            \n",
      "            Linguistic Reasoning: The claim starts with \"Says\", which is a vague and ambiguous way to introduce information, and then lists several unspecific actions attributed to \"Jeff Reardon\" without providing any context or evidence. This lack of specificity and the use of vague language make the claim less credible.\n",
      "True Label:\n",
      "1\n",
      "('FAKE', ['Says', 'Jeff Reardon', 'cut', 'elementary school', 'music classes'], 'The claim starts with \"Says\", which is a vague and ambiguous way to introduce information, and then lists several unspecific actions attributed to \"Jeff Reardon\" without providing any context or evidence. This lack of specificity and the use of vague language make the claim less credible.')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "One in three women is sexually assaulted on the dangerous journey north.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: FAKE\n",
      "\n",
      "Keywords: \"one in three women\", \"sexually assaulted\", \"dangerous journey north\"\n",
      "\n",
      "Linguistic Reasoning: The claim uses an exaggerated statistic and strong emotional language to create a sense of urgency and fear, but it lacks specificity and concrete evidence.\n",
      "True Label:\n",
      "0\n",
      "('FAKE', ['one in three women', 'sexually assaulted', 'dangerous journey north'], 'The claim uses an exaggerated statistic and strong emotional language to create a sense of urgency and fear, but it lacks specificity and concrete evidence.')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "It's actually the safest time to fly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Classification: NEUTRAL\n",
      "\n",
      "Keywords: \"safest time\", \"fly\"\n",
      "\n",
      "Linguistic Reasoning: The claim is vague and lacks clear exaggeration or emotional appeal. It is a subjective statement that can be argued both ways, making it neutral.\n",
      "True Label:\n",
      "1\n",
      "('UNKNOWN', ['safest time', 'fly'], 'The claim is vague and lacks clear exaggeration or emotional appeal. It is a subjective statement that can be argued both ways, making it neutral.')\n",
      "\n",
      "#########################\n",
      "Claim:\n",
      "We know dangerous criminals can slip through immigration at airports just like ours. Yet Joe Donnelly stood right here with the radical left against all efforts to secure our most vulnerable entry points.\n",
      "Model Response:\n",
      "Classification: FAKE\n",
      "\n",
      "Keywords: \"dangerous criminals\", \"slip through immigration\", \"airports\", \"Joe Donnelly\", \"radical left\"\n",
      "\n",
      "Linguistic Reasoning: The claim uses strong emotional language (\"dangerous criminals\"), vague accusations (\"can slip through\"), and polarizing terms (\"radical left\") to create a sense of urgency and fear, potentially manipulating the reader's emotions without providing concrete evidence.\n",
      "True Label:\n",
      "1\n",
      "('FAKE', ['dangerous criminals', 'slip through immigration', 'airports', 'Joe Donnelly', 'radical left'], 'The claim uses strong emotional language (\"dangerous criminals\"), vague accusations (\"can slip through\"), and polarizing terms (\"radical left\") to create a sense of urgency and fear, potentially manipulating the reader\\'s emotions without providing concrete evidence.')\n",
      "\n",
      "#########################\n"
     ]
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "#     train_claim = dataset[\"train\"][\"statement\"][i]\n",
    "#     train_label = dataset[\"train\"][\"label\"][i]\n",
    "#     print(f\"Claim:\\n{train_claim}\")\n",
    "#     formatted_prompt = format_chat_prompt_v2(train_claim)\n",
    "    \n",
    "#     inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "#     output_tokens = model.generate(**inputs, max_new_tokens=150)\n",
    "#     model_response = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "    \n",
    "#     cleaned_response = model_response.split(\"[/INST]\")[-1].strip()\n",
    "#     print(f\"Model Response:\\n{cleaned_response}\")\n",
    "#     print(f\"True Label:\\n{train_label}\")\n",
    "    \n",
    "#     print(extract_prediction(cleaned_response))\n",
    "#     print(\"\\n#########################\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6989174,
     "sourceId": 11195079,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
